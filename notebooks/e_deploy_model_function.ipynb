{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved models\n",
    "svm_model = joblib.load('../trained_models/svm_model.pkl')\n",
    "sgd_model = joblib.load('../trained_models/sgd_model.pkl')\n",
    "rf_model = joblib.load('../trained_models/rf_model.pkl')\n",
    "svm_model_pca = joblib.load('../trained_models/svm_model_pca.pkl')\n",
    "sgd_model_pca = joblib.load('../trained_models/sgd_model_pca.pkl')\n",
    "rf_model_pca = joblib.load('../trained_models/rf_model_pca.pkl')\n",
    "\n",
    "# Define the reference SECOM data structure for compatibility checks\n",
    "secom_reference_data = pd.read_csv('../dataset/secom.data', sep='\\s+', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model(model='RF', data=None, verbose=False, pca=True):\n",
    "    \"\"\"\n",
    "    Deploy the chosen machine learning model for prediction.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_choice : str, optional (default='RF')\n",
    "        The model to use for prediction. Choices are:\n",
    "        - 'SVM': Support Vector Machine model\n",
    "        - 'SGD': Stochastic Gradient Descent Logistic Regression model\n",
    "        - 'RF' : Random Forest model\n",
    "\n",
    "    data : pd.DataFrame or np.array\n",
    "        The data that needs to be predicted. Can be a single row (stream) or multiple rows.\n",
    "        The number of features must match the reference SECOM data.\n",
    "\n",
    "    verbose : bool, optional (default=False)\n",
    "        If True, print detailed information during the process.\n",
    "\n",
    "    use_pca : bool, optional (default=True)\n",
    "        If True, apply PCA transformation to the data before prediction.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    predictions : np.ndarray\n",
    "        The predicted labels for the input data.\n",
    "    \"\"\"\n",
    "    # Choose the model\n",
    "    if pca:\n",
    "        model_dict = {\n",
    "            'SVM': svm_model_pca,\n",
    "            'SGD': sgd_model_pca,\n",
    "            'RF': rf_model_pca\n",
    "        }\n",
    "    else: \n",
    "        model_dict = {\n",
    "            'SVM': svm_model,\n",
    "            'SGD': sgd_model,\n",
    "            'RF': rf_model\n",
    "        }\n",
    "\n",
    "    model = model_dict.get(model, rf_model_pca)  # Default to RF model\n",
    "    \n",
    "    # Convert single row of data to the correct format (ensure it's 2D)\n",
    "    if isinstance(data, pd.DataFrame) or isinstance(data, np.ndarray):\n",
    "        if data.ndim == 1:  # Single row, reshape it to (1, -1)\n",
    "            data = data.reshape(1, -1) if isinstance(data, np.ndarray) else data.values.reshape(1, -1)\n",
    "\n",
    "    # Check if data is compatible with reference SECOM data (feature length match)\n",
    "    if data.shape[1] != secom_reference_data.shape[1]:\n",
    "        raise ValueError(f\"Data has {data.shape[1]} features, but expected {secom_reference_data.shape[1]} features.\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Chosen model: {model}\")\n",
    "\n",
    "    # Check for missing features and impute them if necessary\n",
    "    missing_columns = set(secom_reference_data.columns) - set(range(data.shape[1]))\n",
    "    if missing_columns:\n",
    "        if verbose:\n",
    "            print(f\"Missing features: {missing_columns}\")\n",
    "        # Add missing columns with NaN values\n",
    "        for col in missing_columns:\n",
    "            data[col] = np.nan\n",
    "\n",
    "    # Impute missing values using the same imputation strategy used during training\n",
    "    imputer = SimpleImputer(strategy='mean').set_output(transform=\"pandas\")\n",
    "    data_imputed = imputer.fit_transform(data)\n",
    "\n",
    "    # Normalize/scale the input data to improve the result\n",
    "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "    data_scaled = scaler.fit_transform(data_imputed)\n",
    "\n",
    "    # Apply PCA if specified\n",
    "    if pca:\n",
    "        pca = PCA(n_components=158).set_output(transform=\"pandas\")  # same as training PCA component size\n",
    "        data_transformed = pca.fit_transform(data_scaled)\n",
    "        if verbose:\n",
    "            print(\"PCA applied.\")\n",
    "    else:\n",
    "        data_transformed = data_scaled\n",
    "        if verbose:\n",
    "            print(\"PCA not applied.\")\n",
    "\n",
    "    # Predict using the chosen model\n",
    "    predictions = model.predict(data_transformed)\n",
    "    \n",
    "    # Display results\n",
    "    if verbose:\n",
    "        print(\"Predictions:\")\n",
    "        print(predictions)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen model: BaggingClassifier(estimator=RandomForestClassifier(class_weight='balanced',\n",
      "                                                   max_depth=10,\n",
      "                                                   random_state=42),\n",
      "                  random_state=42)\n",
      "PCA applied.\n",
      "Predictions:\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Let's try the function\n",
    "predict_result = deploy_model(data=secom_reference_data, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
